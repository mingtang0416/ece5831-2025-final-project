{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33861f95",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-21T18:57:07.886642Z",
     "iopub.status.busy": "2025-11-21T18:57:07.886436Z",
     "iopub.status.idle": "2025-11-21T18:57:08.013670Z",
     "shell.execute_reply": "2025-11-21T18:57:08.012756Z"
    },
    "papermill": {
     "duration": 0.132194,
     "end_time": "2025-11-21T18:57:08.014990",
     "exception": false,
     "start_time": "2025-11-21T18:57:07.882796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing contents of /kaggle/input/:\n",
      "v2-cam1-cam2-split-by-driver\r\n",
      "\n",
      "Confirmed DATASET_SLUG: v2-cam1-cam2-split-by-driver\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Listing contents of /kaggle/input/:\")\n",
    "!ls /kaggle/input/\n",
    "\n",
    "\n",
    "DATASET_SLUG = \"v2-cam1-cam2-split-by-driver\" \n",
    "\n",
    "print(f\"\\nConfirmed DATASET_SLUG: {DATASET_SLUG}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47feb023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:57:08.021655Z",
     "iopub.status.busy": "2025-11-21T18:57:08.021371Z",
     "iopub.status.idle": "2025-11-21T18:57:08.640036Z",
     "shell.execute_reply": "2025-11-21T18:57:08.639167Z"
    },
    "papermill": {
     "duration": 0.623776,
     "end_time": "2025-11-21T18:57:08.641440",
     "exception": false,
     "start_time": "2025-11-21T18:57:08.017664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listing contents of /kaggle/input/v2-cam1-cam2-split-by-driver/:\n",
      "v2_cam1_cam2_split_by_driver\r\n",
      "\n",
      "Corrected DATASET_ROOT is: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/\n",
      "\n",
      "Listing contents of: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/\n",
      "'Camera 1'  'Camera 2'\t skin_nonskin_pixels\r\n",
      "\n",
      "Listing contents of Camera 1:\n",
      "test  train\r\n",
      "\n",
      "Listing contents of Camera 1/train:\n",
      "c0  c1\tc2  c3\tc4  c5\tc6  c7\tc8  c9\r\n",
      "\n",
      "Listing contents of Camera 1/train/c0 (first 5 files):\n",
      "1000.jpg\r\n",
      "1001.jpg\r\n",
      "1002.jpg\r\n",
      "1003.jpg\r\n",
      "1004.jpg\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATASET_SLUG = \"v2-cam1-cam2-split-by-driver\" \n",
    "\n",
    "print(f\"\\nListing contents of /kaggle/input/{DATASET_SLUG}/:\")\n",
    "!ls \"/kaggle/input/{DATASET_SLUG}/\"\n",
    "\n",
    "\n",
    "INTERNAL_TOP_LEVEL_FOLDER = \"v2_cam1_cam2_split_by_driver\" \n",
    "\n",
    "DATASET_ROOT = f\"/kaggle/input/{DATASET_SLUG}/{INTERNAL_TOP_LEVEL_FOLDER}/\"\n",
    "\n",
    "print(f\"\\nCorrected DATASET_ROOT is: {DATASET_ROOT}\")\n",
    "\n",
    "print(f\"\\nListing contents of: {DATASET_ROOT}\")\n",
    "!ls \"{DATASET_ROOT}\"\n",
    "\n",
    "print(\"\\nListing contents of Camera 1:\")\n",
    "!ls \"{DATASET_ROOT}Camera 1/\"\n",
    "\n",
    "print(\"\\nListing contents of Camera 1/train:\")\n",
    "!ls \"{DATASET_ROOT}Camera 1/train/\"\n",
    "\n",
    "print(\"\\nListing contents of Camera 1/train/c0 (first 5 files):\")\n",
    "!ls \"{DATASET_ROOT}Camera 1/train/c0/\" | head -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02246c4",
   "metadata": {
    "papermill": {
     "duration": 0.002598,
     "end_time": "2025-11-21T18:57:08.646765",
     "exception": false,
     "start_time": "2025-11-21T18:57:08.644167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "define path and configurationimport os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2684e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:57:08.652959Z",
     "iopub.status.busy": "2025-11-21T18:57:08.652747Z",
     "iopub.status.idle": "2025-11-21T18:57:12.254700Z",
     "shell.execute_reply": "2025-11-21T18:57:12.253845Z"
    },
    "papermill": {
     "duration": 3.606631,
     "end_time": "2025-11-21T18:57:12.255817",
     "exception": false,
     "start_time": "2025-11-21T18:57:08.649186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment cleaned: old pseudo-labels removed.\n",
      "Configuration loaded.\n",
      "Dataset root: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/\n",
      "Pseudo-labels will be generated to: /kaggle/working/yolo_pseudo_labels/\n",
      "Pseudo-labels will be packed to: /kaggle/working/output/yolo_pseudo_labels_packed.tar.gz\n",
      "Directory structure for new pseudo-labels created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "PSEUDO_LABELS_ROOT_TEMP = '/kaggle/working/yolo_pseudo_labels/'\n",
    "PSEUDO_LABELS_TARGZ_TEMP = '/kaggle/working/output/yolo_pseudo_labels_packed.tar.gz'\n",
    "\n",
    "if os.path.exists(PSEUDO_LABELS_ROOT_TEMP):\n",
    "    print(f\"Removing old pseudo-labels directory: {PSEUDO_LABELS_ROOT_TEMP}\")\n",
    "    !rm -rf \"{PSEUDO_LABELS_ROOT_TEMP}\"\n",
    "\n",
    "if os.path.exists(PSEUDO_LABELS_TARGZ_TEMP):\n",
    "    print(f\"Removing old pseudo-labels zip: {PSEUDO_LABELS_TARGZ_TEMP}\")\n",
    "    !rm -f \"{PSEUDO_LABELS_TARGZ_TEMP}\"\n",
    "\n",
    "print(\"\\nEnvironment cleaned: old pseudo-labels removed.\")\n",
    "\n",
    "# --- config path ---\n",
    "DATASET_ROOT = '/kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/'\n",
    "\n",
    "PSEUDO_LABELS_ROOT = '/kaggle/working/yolo_pseudo_labels/'\n",
    "PSEUDO_LABELS_TARGZ_LOCAL_PATH = '/kaggle/working/output/yolo_pseudo_labels_packed.tar.gz'\n",
    "\n",
    "SUB_DIRS = [\n",
    "    'Camera 1/train', 'Camera 1/test', 'Camera 2/train', 'Camera 2/test',\n",
    "]\n",
    "\n",
    "# --- YOLOv8 configuration ---\n",
    "MODEL_NAME = 'yolov8n.pt'\n",
    "CONF_THRESHOLD = 0.5\n",
    "COCO_CLASSES_TO_PSEUDO_LABEL = {\n",
    "    0: 'person', 39: 'bottle', 41: 'cup', 67: 'cell phone',\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Dataset root: {DATASET_ROOT}\")\n",
    "print(f\"Pseudo-labels will be generated to: {PSEUDO_LABELS_ROOT}\")\n",
    "print(f\"Pseudo-labels will be packed to: {PSEUDO_LABELS_TARGZ_LOCAL_PATH}\")\n",
    "\n",
    "SKIP_PSEUDO_LABEL_GENERATION = False\n",
    "\n",
    "if SKIP_PSEUDO_LABEL_GENERATION:\n",
    "    pass\n",
    "else:\n",
    "    for sub_dir in SUB_DIRS:\n",
    "        for i in range(10):\n",
    "            class_folder = f\"c{i}\"\n",
    "            os.makedirs(os.path.join(PSEUDO_LABELS_ROOT, sub_dir, class_folder), exist_ok=True)\n",
    "    print(\"Directory structure for new pseudo-labels created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715a16d8",
   "metadata": {
    "papermill": {
     "duration": 0.002323,
     "end_time": "2025-11-21T18:57:12.260797",
     "exception": false,
     "start_time": "2025-11-21T18:57:12.258474",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Setting up the YOLOv8 environment (installing the Ultralytics package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938eae56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:57:12.266703Z",
     "iopub.status.busy": "2025-11-21T18:57:12.266411Z",
     "iopub.status.idle": "2025-11-21T18:57:37.083585Z",
     "shell.execute_reply": "2025-11-21T18:57:37.082511Z"
    },
    "papermill": {
     "duration": 24.821524,
     "end_time": "2025-11-21T18:57:37.084924",
     "exception": false,
     "start_time": "2025-11-21T18:57:12.263400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n",
      "\n",
      "Attempting to clone ultralytics repository...\n",
      "Cloning into 'ultralytics_repo'...\r\n",
      "remote: Enumerating objects: 73881, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (358/358), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (120/120), done.\u001b[K\r\n",
      "remote: Total 73881 (delta 293), reused 240 (delta 238), pack-reused 73523 (from 3)\u001b[K\r\n",
      "Receiving objects: 100% (73881/73881), 39.73 MiB | 30.85 MiB/s, done.\r\n",
      "Resolving deltas: 100% (55454/55454), done.\r\n",
      "/kaggle/working/ultralytics_repo\n",
      "\n",
      "Forcibly installing compatible numpy and matplotlib versions...\n",
      "Collecting numpy==1.26.4\r\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting matplotlib==3.7.2\r\n",
      "  Downloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\r\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading matplotlib-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: numpy, matplotlib\r\n",
      "  Attempting uninstall: numpy\r\n",
      "    Found existing installation: numpy 1.26.4\r\n",
      "    Uninstalling numpy-1.26.4:\r\n",
      "      Successfully uninstalled numpy-1.26.4\r\n",
      "  Attempting uninstall: matplotlib\r\n",
      "    Found existing installation: matplotlib 3.7.2\r\n",
      "    Uninstalling matplotlib-3.7.2:\r\n",
      "      Successfully uninstalled matplotlib-3.7.2\r\n",
      "Successfully installed matplotlib-3.7.2 numpy-1.26.4\r\n",
      "\n",
      "Installing ultralytics package and its dependencies...\n",
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.3.229-py3-none-any.whl.metadata (37 kB)\r\n",
      "Downloading ultralytics-8.3.229-py3-none-any.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ultralytics\r\n",
      "Successfully installed ultralytics-8.3.229\r\n",
      "\n",
      "YOLOv8 environment setup complete, with NumPy compatibility fix.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%cd /kaggle/working/\n",
    "\n",
    "# 2. Clone the Ultralytics repository\n",
    "print(\"\\nAttempting to clone ultralytics repository...\")\n",
    "!git clone https://github.com/ultralytics/ultralytics.git ultralytics_repo\n",
    "%cd ultralytics_repo\n",
    "\n",
    "print(\"\\nForcibly installing compatible numpy and matplotlib versions...\")\n",
    "!pip install --force-reinstall --no-deps numpy==1.26.4 matplotlib==3.7.2\n",
    "\n",
    "# 3. install ultralytics package (YOLOv8)\n",
    "\n",
    "print(\"\\nInstalling ultralytics package and its dependencies...\")\n",
    "!pip install --no-deps ultralytics\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nYOLOv8 environment setup complete, with NumPy compatibility fix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5a6cee",
   "metadata": {
    "papermill": {
     "duration": 0.005779,
     "end_time": "2025-11-21T18:57:37.097225",
     "exception": false,
     "start_time": "2025-11-21T18:57:37.091446",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Load the pre-trained YOLOv8 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966de6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:57:37.109974Z",
     "iopub.status.busy": "2025-11-21T18:57:37.109724Z",
     "iopub.status.idle": "2025-11-21T18:57:37.985981Z",
     "shell.execute_reply": "2025-11-21T18:57:37.984999Z"
    },
    "papermill": {
     "duration": 0.884714,
     "end_time": "2025-11-21T18:57:37.987595",
     "exception": false,
     "start_time": "2025-11-21T18:57:37.102881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\n",
      "Loading pre-trained YOLOv8 model 'yolov8n.pt'...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 64.2MB/s 0.1s\n",
      "YOLOv8 model 'yolov8n.pt' loaded with confidence threshold 0.5.\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "if not SKIP_PSEUDO_LABEL_GENERATION:\n",
    "    # --- Load the pre-trained YOLOv8 model ---\n",
    "    print(f\"\\nLoading pre-trained YOLOv8 model '{MODEL_NAME}'...\")\n",
    "\n",
    "    model = YOLO(MODEL_NAME) \n",
    "\n",
    "    # Set the confidence threshold for detection (specified in the predict() method in YOLOv8)\n",
    "    # model.conf = CONF_THRESHOLD \n",
    "\n",
    "    print(f\"YOLOv8 model '{MODEL_NAME}' loaded with confidence threshold {CONF_THRESHOLD}.\")\n",
    "else:\n",
    "    print(\"\\nSkipping YOLOv8 model loading as pseudo-labels already exist.\")\n",
    "    # Define a None model to ensure that subsequent code will not call it accidentally\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa91bb1d",
   "metadata": {
    "papermill": {
     "duration": 0.00581,
     "end_time": "2025-11-21T18:57:38.001565",
     "exception": false,
     "start_time": "2025-11-21T18:57:37.995755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Traverse images and generate pseudo tags遍历图片并生成伪标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3745522",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T18:57:38.015276Z",
     "iopub.status.busy": "2025-11-21T18:57:38.014977Z",
     "iopub.status.idle": "2025-11-21T19:03:52.424815Z",
     "shell.execute_reply": "2025-11-21T19:03:52.423854Z"
    },
    "papermill": {
     "duration": 374.418589,
     "end_time": "2025-11-21T19:03:52.426248",
     "exception": false,
     "start_time": "2025-11-21T18:57:38.007659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting pseudo-label generation for 4 sub-directories ---\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c0\n",
      "  - Processing 2440 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c0...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c1\n",
      "  - Processing 1305 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c1...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c2\n",
      "  - Processing 862 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c2...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c3\n",
      "  - Processing 744 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c3...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c4\n",
      "  - Processing 950 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c4...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c5\n",
      "  - Processing 753 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c5...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c6\n",
      "  - Processing 733 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c6...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c7\n",
      "  - Processing 691 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c7...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c8\n",
      "  - Processing 698 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c8...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c9\n",
      "  - Processing 1379 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/train/c9...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c0\n",
      "  - Processing 266 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c0...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c1\n",
      "  - Processing 133 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c1...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c2\n",
      "  - Processing 114 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c2...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c3\n",
      "  - Processing 100 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c3...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c4\n",
      "  - Processing 90 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c4...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c5\n",
      "  - Processing 90 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c5...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c6\n",
      "  - Processing 63 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c6...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c7\n",
      "  - Processing 63 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c7...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c8\n",
      "  - Processing 66 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c8...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c9\n",
      "  - Processing 138 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 1/test/c9...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c0\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c0...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c1\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c1...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c2\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c2...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c3\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c3...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c4\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c4...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c5\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c5...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c6\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c6...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c7\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c7...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c8\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c8...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c9\n",
      "  - Processing 200 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/train/c9...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c0\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c0...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c1\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c1...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c2\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c2...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c3\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c3...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c4\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c4...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c5\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c5...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c6\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c6...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c7\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c7...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c8\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c8...\n",
      "Processing folder: /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c9\n",
      "  - Processing 80 images in /kaggle/input/v2-cam1-cam2-split-by-driver/v2_cam1_cam2_split_by_driver/Camera 2/test/c9...\n",
      "\n",
      "--- Pseudo-label generation complete! ---\n",
      "All generated pseudo-labels are saved to: /kaggle/working/yolo_pseudo_labels/\n",
      "\n",
      "--- Packaging pseudo-labels for persistence to /kaggle/working/output/yolo_pseudo_labels_packed.tar.gz using tar ---\n",
      "/kaggle/working/yolo_pseudo_labels\n",
      "tar: Substituting `.' for empty member name\r\n",
      "tar: : Cannot stat: No such file or directory\r\n",
      "tar: Exiting with failure status due to previous errors\r\n",
      "/kaggle/working/ultralytics_repo\n",
      "Successfully created tar.gz file: /kaggle/working/output/yolo_pseudo_labels_packed.tar.gz\n",
      "File size: 0.00 MB\n",
      "Please refresh the Kaggle file browser to see the .tar.gz file, then 'Save Version' of your Notebook.\n"
     ]
    }
   ],
   "source": [
    "if not SKIP_PSEUDO_LABEL_GENERATION:\n",
    "    # --- Pseudo-label generation function  ---\n",
    "    def generate_pseudo_labels(image_dir, label_output_dir):\n",
    "        image_files = glob.glob(os.path.join(image_dir, '*.jpg')) \n",
    "        if not image_files:\n",
    "            print(f\"  - No .jpg images found in {image_dir}\")\n",
    "            return\n",
    "\n",
    "        print(f\"  - Processing {len(image_files)} images in {image_dir}...\")\n",
    "\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                results = model.predict(source=img_path, conf=CONF_THRESHOLD, verbose=False)[0]\n",
    "                \n",
    "                img_width, img_height = results.orig_shape[1], results.orig_shape[0]\n",
    "                label_filename = os.path.join(label_output_dir, os.path.basename(img_path).replace('.jpg', '.txt'))\n",
    "                \n",
    "                with open(label_filename, 'w') as f:\n",
    "                    for box in results.boxes:\n",
    "                        cls_id = int(box.cls.item())\n",
    "                        conf = box.conf.item()\n",
    "                        xywhn = box.xywhn.tolist()[0]\n",
    "\n",
    "                        if cls_id in COCO_CLASSES_TO_PSEUDO_LABEL:\n",
    "                            f.write(f\"{cls_id} {xywhn[0]:.6f} {xywhn[1]:.6f} {xywhn[2]:.6f} {xywhn[3]:.6f}\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  - Error processing {img_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # --- Traverse all subdirectories and generate pseudo tags ---\n",
    "    print(f\"\\n--- Starting pseudo-label generation for {len(SUB_DIRS)} sub-directories ---\")\n",
    "    for sub_dir in SUB_DIRS:\n",
    "        full_sub_dir_path = os.path.join(DATASET_ROOT, sub_dir)\n",
    "        output_label_sub_dir = os.path.join(PSEUDO_LABELS_ROOT, sub_dir)\n",
    "\n",
    "        for i in range(10):\n",
    "            class_folder = f\"c{i}\"\n",
    "            image_class_dir = os.path.join(full_sub_dir_path, class_folder)\n",
    "            label_class_output_dir = os.path.join(output_label_sub_dir, class_folder)\n",
    "            \n",
    "            os.makedirs(label_class_output_dir, exist_ok=True) \n",
    "            \n",
    "            print(f\"Processing folder: {image_class_dir}\")\n",
    "            generate_pseudo_labels(image_class_dir, label_class_output_dir)\n",
    "\n",
    "    print(\"\\n--- Pseudo-label generation complete! ---\")\n",
    "    print(f\"All generated pseudo-labels are saved to: {PSEUDO_LABELS_ROOT}\")\n",
    "\n",
    "    # --- Package and save the generated pseudo-tags to the Kaggle Output folder ---\n",
    "    print(f\"\\n--- Packaging pseudo-labels for persistence to {PSEUDO_LABELS_TARGZ_LOCAL_PATH} using tar ---\")\n",
    "    os.makedirs(os.path.dirname(PSEUDO_LABELS_TARGZ_LOCAL_PATH), exist_ok=True)\n",
    "    \n",
    "    current_dir = os.getcwd()\n",
    "    %cd {os.path.dirname(PSEUDO_LABELS_ROOT)} \n",
    "    \n",
    "    !tar -czf \"{PSEUDO_LABELS_TARGZ_LOCAL_PATH}\" \"{os.path.basename(PSEUDO_LABELS_ROOT)}\"\n",
    "\n",
    "    %cd {current_dir}\n",
    "\n",
    "    if os.path.exists(PSEUDO_LABELS_TARGZ_LOCAL_PATH):\n",
    "        print(f\"Successfully created tar.gz file: {PSEUDO_LABELS_TARGZ_LOCAL_PATH}\")\n",
    "        print(f\"File size: {os.path.getsize(PSEUDO_LABELS_TARGZ_LOCAL_PATH) / (1024*1024):.2f} MB\")\n",
    "        print(\"Please refresh the Kaggle file browser to see the .tar.gz file, then 'Save Version' of your Notebook.\")\n",
    "    else:\n",
    "        print(f\"Error: Failed to create tar.gz file at {PSEUDO_LABELS_TARGZ_LOCAL_PATH}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping pseudo-label generation as existing labels were loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f7e48",
   "metadata": {
    "papermill": {
     "duration": 0.007254,
     "end_time": "2025-11-21T19:03:52.441358",
     "exception": false,
     "start_time": "2025-11-21T19:03:52.434104",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Packaging pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8d725e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T19:03:52.458392Z",
     "iopub.status.busy": "2025-11-21T19:03:52.457834Z",
     "iopub.status.idle": "2025-11-21T19:03:52.819940Z",
     "shell.execute_reply": "2025-11-21T19:03:52.818990Z"
    },
    "papermill": {
     "duration": 0.372083,
     "end_time": "2025-11-21T19:03:52.821237",
     "exception": false,
     "start_time": "2025-11-21T19:03:52.449154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Packaging pseudo-labels to /kaggle/working/yolo_pseudo_labels_packed.tar.gz using tar ---\n",
      "/kaggle/working/yolo_pseudo_labels\n",
      "/kaggle/working/ultralytics_repo\n",
      "Successfully created tar.gz file: /kaggle/working/yolo_pseudo_labels_packed.tar.gz\n",
      "File size: 0.48 MB\n",
      "\n",
      "Please refresh the Kaggle file browser to see the .tar.gz file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the source directory for pseudo-tags\n",
    "PSEUDO_LABELS_SOURCE_DIR = '/kaggle/working/yolo_pseudo_labels/'\n",
    "# Define the output path and filename of the compressed file\n",
    "PSEUDO_LABELS_TARGZ_LOCAL_PATH = '/kaggle/working/yolo_pseudo_labels_packed.tar.gz' \n",
    "\n",
    "print(f\"\\n--- Packaging pseudo-labels to {PSEUDO_LABELS_TARGZ_LOCAL_PATH} using tar ---\")\n",
    "\n",
    "os.makedirs(os.path.dirname(PSEUDO_LABELS_TARGZ_LOCAL_PATH), exist_ok=True)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "%cd {PSEUDO_LABELS_SOURCE_DIR}\n",
    "\n",
    "!tar -czf \"../yolo_pseudo_labels_packed.tar.gz\" .\n",
    "\n",
    "%cd {current_dir}\n",
    "\n",
    "if os.path.exists(PSEUDO_LABELS_TARGZ_LOCAL_PATH):\n",
    "    print(f\"Successfully created tar.gz file: {PSEUDO_LABELS_TARGZ_LOCAL_PATH}\")\n",
    "    print(f\"File size: {os.path.getsize(PSEUDO_LABELS_TARGZ_LOCAL_PATH) / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    print(\"\\nPlease refresh the Kaggle file browser to see the .tar.gz file.\")\n",
    "else:\n",
    "    print(f\"Error: Failed to create tar.gz file at {PSEUDO_LABELS_TARGZ_LOCAL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3ba499",
   "metadata": {
    "papermill": {
     "duration": 0.007748,
     "end_time": "2025-11-21T19:03:52.836971",
     "exception": false,
     "start_time": "2025-11-21T19:03:52.829223",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "move tar to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828bd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-21T19:03:52.853408Z",
     "iopub.status.busy": "2025-11-21T19:03:52.853057Z",
     "iopub.status.idle": "2025-11-21T19:03:52.992328Z",
     "shell.execute_reply": "2025-11-21T19:03:52.991474Z"
    },
    "papermill": {
     "duration": 0.149024,
     "end_time": "2025-11-21T19:03:52.993587",
     "exception": false,
     "start_time": "2025-11-21T19:03:52.844563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved yolo_pseudo_labels_packed.tar.gz to /kaggle/working/output/yolo_pseudo_labels_packed.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the pseudo-tag archive in /kaggle/working/\n",
    "PSEUDO_LABELS_TARGZ_LOCAL_PATH = '/kaggle/working/yolo_pseudo_labels_packed.tar.gz'\n",
    "# Define the target output path\n",
    "KAGGLE_OUTPUT_DIR = '/kaggle/working/output/'\n",
    "FINAL_PERSISTENT_PATH = os.path.join(KAGGLE_OUTPUT_DIR, os.path.basename(PSEUDO_LABELS_TARGZ_LOCAL_PATH))\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(KAGGLE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# move file\n",
    "if os.path.exists(PSEUDO_LABELS_TARGZ_LOCAL_PATH):\n",
    "    !mv \"{PSEUDO_LABELS_TARGZ_LOCAL_PATH}\" \"{FINAL_PERSISTENT_PATH}\"\n",
    "    print(f\"Moved {os.path.basename(PSEUDO_LABELS_TARGZ_LOCAL_PATH)} to {FINAL_PERSISTENT_PATH}\")\n",
    "else:\n",
    "    print(f\"Error: {PSEUDO_LABELS_TARGZ_LOCAL_PATH} does not exist. Please check previous steps.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8800294,
     "sourceId": 13819128,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 409.83414,
   "end_time": "2025-11-21T19:03:54.220870",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-21T18:57:04.386730",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
